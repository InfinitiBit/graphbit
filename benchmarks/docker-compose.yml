services:
  graphbit-benchmark:
    build:
      # Build context is benchmarks directory only (not parent)
      context: .
      dockerfile: Dockerfile
    container_name: graphbit-benchmark
    environment:
      # LLM Provider API Keys
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      # Azure OpenAI
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION:-2025-01-01-preview}
      # Python configuration
      - PYTHONUNBUFFERED=1
      - PYTHONUTF8=1
      # Logging
      - RUST_LOG=${RUST_LOG:-info}
    volumes:
      # Results and logs with relative paths
      - ./logs:/app/benchmarks/logs
      - ./results:/app/benchmarks/results
      # Optional: Mount source code for development (read-only)
      # - ./:/app/benchmarks:ro
    working_dir: /app/benchmarks
    command: [run_benchmark.py, --help]
    # No resource limits - use full host resources (28 CPUs, 15GB RAM)
    # Note: deploy: section is ignored in standalone Docker Compose mode anyway
    # Optional: Add network for isolation
    # networks:
    #   - benchmark-network
# Optional: Named volumes for persistence
# volumes:
#   benchmark-logs:
#   benchmark-results:

# Optional: Network isolation
# networks:
#   benchmark-network:
#     driver: bridge
