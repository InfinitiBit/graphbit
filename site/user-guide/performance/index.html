
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../monitoring/">
      
      
        <link rel="next" href="../reliability/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>Performance - GraphBits AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#performance-optimization" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="GraphBits AI" class="md-header__button md-logo" aria-label="GraphBits AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            GraphBits AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Performance
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="GraphBits AI" class="md-nav__button md-logo" aria-label="GraphBits AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    GraphBits AI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quickstart
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    User Guide
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            User Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../concepts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Concepts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Agents
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../async-vs-sync/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Async vs Sync
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamics-graph/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dynamics Graph
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../embeddings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llm-providers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLM Providers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../monitoring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Monitoring
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Performance
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Performance
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#execution-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Execution Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Execution Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallel-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Parallel Processing
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#executor-types-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      Executor Types for Performance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Executor Types for Performance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#different-executor-configurations" class="md-nav__link">
    <span class="md-ellipsis">
      Different Executor Configurations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resource-management" class="md-nav__link">
    <span class="md-ellipsis">
      Resource Management
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Resource Management">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#memory-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Configuration Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#environment-specific-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Environment-Specific Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-client-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Client Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Client Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#client-configuration-and-performance" class="md-nav__link">
    <span class="md-ellipsis">
      Client Configuration and Performance
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#workflow-design-patterns-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      Workflow Design Patterns for Performance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Workflow Design Patterns for Performance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#efficient-workflow-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      Efficient Workflow Patterns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-monitoring-and-profiling" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Monitoring and Profiling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Monitoring and Profiling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#real-time-performance-tracking" class="md-nav__link">
    <span class="md-ellipsis">
      Real-time Performance Tracking
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#caching-and-optimization-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Caching and Optimization Strategies
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Caching and Optimization Strategies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#response-caching" class="md-nav__link">
    <span class="md-ellipsis">
      Response Caching
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Best Practices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Best Practices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-choose-the-right-executor-type" class="md-nav__link">
    <span class="md-ellipsis">
      1. Choose the Right Executor Type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-model-selection-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      2. Model Selection for Performance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-workflow-design-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      3. Workflow Design for Performance
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-testing-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Testing Framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Testing Framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#automated-performance-testing" class="md-nav__link">
    <span class="md-ellipsis">
      Automated Performance Testing
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#whats-next" class="md-nav__link">
    <span class="md-ellipsis">
      What's Next
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reliability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Reliability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../text-splitters/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Text Splitters
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../validation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Validation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../workflow-builder/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Workflow Builder
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api-reference/configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Configuration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api-reference/node-types/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Node Types
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api-reference/python-api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python API
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Connector Integrations
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Connector Integrations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/aws_boto3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AWS Boto3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/chromadb_integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ChromaDB Integration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/faiss_integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FAISS Integration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/google_search_api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Google Search API
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/mariadb_integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MariaDB Integration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/milvus_integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Milvus Integration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/mongodb/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MongoDB
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/pgvector/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    PGVector
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/pinecone_integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pinecone Integration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/qdrant_integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qdrant Integration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../connector/weaviate_integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Weaviate Integration
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Development
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Development
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Architecture
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/debugging/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Debugging
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../development/python-bindings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Bindings
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/comprehensive-pipeline/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comprehensive Pipeline
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/content-generation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Content Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/data-processing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data Processing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/llm-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLM Integration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/semantic-search/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Semantic Search
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#execution-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Execution Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Execution Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallel-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Parallel Processing
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#executor-types-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      Executor Types for Performance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Executor Types for Performance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#different-executor-configurations" class="md-nav__link">
    <span class="md-ellipsis">
      Different Executor Configurations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resource-management" class="md-nav__link">
    <span class="md-ellipsis">
      Resource Management
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Resource Management">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#memory-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Configuration Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#environment-specific-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Environment-Specific Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-client-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Client Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Client Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#client-configuration-and-performance" class="md-nav__link">
    <span class="md-ellipsis">
      Client Configuration and Performance
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#workflow-design-patterns-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      Workflow Design Patterns for Performance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Workflow Design Patterns for Performance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#efficient-workflow-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      Efficient Workflow Patterns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-monitoring-and-profiling" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Monitoring and Profiling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Monitoring and Profiling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#real-time-performance-tracking" class="md-nav__link">
    <span class="md-ellipsis">
      Real-time Performance Tracking
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#caching-and-optimization-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Caching and Optimization Strategies
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Caching and Optimization Strategies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#response-caching" class="md-nav__link">
    <span class="md-ellipsis">
      Response Caching
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Best Practices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Best Practices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-choose-the-right-executor-type" class="md-nav__link">
    <span class="md-ellipsis">
      1. Choose the Right Executor Type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-model-selection-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      2. Model Selection for Performance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-workflow-design-for-performance" class="md-nav__link">
    <span class="md-ellipsis">
      3. Workflow Design for Performance
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-testing-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Testing Framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Testing Framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#automated-performance-testing" class="md-nav__link">
    <span class="md-ellipsis">
      Automated Performance Testing
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#whats-next" class="md-nav__link">
    <span class="md-ellipsis">
      What's Next
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="performance-optimization">Performance Optimization</h1>
<p>GraphBit provides multiple strategies for optimizing workflow performance, from execution patterns to resource management. This guide covers techniques to maximize throughput, minimize latency, and optimize resource usage.</p>
<h2 id="overview">Overview</h2>
<p>Performance optimization in GraphBit focuses on:
- <strong>Execution Optimization</strong>: Parallel processing and efficient node execution
- <strong>Resource Management</strong>: Memory, CPU, and network optimization<br />
- <strong>Caching Strategies</strong>: Reducing redundant computations
- <strong>Configuration Tuning</strong>: Optimal settings for different scenarios
- <strong>Monitoring &amp; Profiling</strong>: Identifying and resolving bottlenecks</p>
<h2 id="execution-optimization">Execution Optimization</h2>
<h3 id="parallel-processing">Parallel Processing</h3>
<pre><code class="language-python">import graphbit
import time
import os

# Initialize GraphBit
graphbit.init()

def create_parallel_workflow():
    &quot;&quot;&quot;Create workflow optimized for parallel execution.&quot;&quot;&quot;

    workflow = graphbit.Workflow(&quot;Parallel Processing Workflow&quot;)

    # Input processor
    input_processor = graphbit.Node.agent(
        name=&quot;Input Processor&quot;,
        prompt=&quot;Prepare data for parallel processing: {input}&quot;,
        agent_id=&quot;input_processor&quot;
    )

    # Parallel processing branches
    branch_nodes = []
    for i in range(4):  # Create 4 parallel branches
        branch = graphbit.Node.agent(
            name=f&quot;Parallel Branch {i+1}&quot;,
            prompt=f&quot;Process branch {i+1} data: {{prepared_data}}&quot;,
            agent_id=f&quot;branch_{i+1}&quot;
        )
        branch_nodes.append(branch)

    # Results aggregator
    aggregator = graphbit.Node.agent(
        name=&quot;Results Aggregator&quot;,
        prompt=&quot;&quot;&quot;
        Combine results from parallel branches:
        Branch 1: {branch_1_output}
        Branch 2: {branch_2_output}
        Branch 3: {branch_3_output}
        Branch 4: {branch_4_output}
        &quot;&quot;&quot;,
        agent_id=&quot;aggregator&quot;
    )

    # Build parallel structure
    input_id = workflow.add_node(input_processor)
    branch_ids = [workflow.add_node(branch) for branch in branch_nodes]
    agg_id = workflow.add_node(aggregator)

    # Connect input to all branches (fan-out)
    for branch_id in branch_ids:
        workflow.connect(input_id, branch_id)

    # Connect all branches to aggregator (fan-in)
    for branch_id in branch_ids:
        workflow.connect(branch_id, agg_id)

    return workflow

def create_performance_optimized_executor():
    &quot;&quot;&quot;Create executor optimized for performance.&quot;&quot;&quot;

    # Use fast, cost-effective model
    config = graphbit.LlmConfig.openai(
        api_key=os.getenv(&quot;OPENAI_API_KEY&quot;),
        model=&quot;gpt-4o-mini&quot;  # Fast and efficient model
    )

    # Create high-performance executor
    executor = graphbit.Executor.new_high_throughput(
        llm_config=config,
        timeout_seconds=60,
        debug=False
    )

    return executor
</code></pre>
<h2 id="executor-types-for-performance">Executor Types for Performance</h2>
<h3 id="different-executor-configurations">Different Executor Configurations</h3>
<pre><code class="language-python">def create_optimized_executors():
    &quot;&quot;&quot;Create different executor types for various performance needs.&quot;&quot;&quot;

    # Base LLM configuration
    llm_config = graphbit.LlmConfig.openai(
        api_key=os.getenv(&quot;OPENAI_API_KEY&quot;),
        model=&quot;gpt-4o-mini&quot;
    )

    executors = {}

    # Standard executor - balanced performance
    executors[&quot;standard&quot;] = graphbit.Executor(
        config=llm_config,
        timeout_seconds=60,
        debug=False
    )

    # High-throughput executor - maximize parallel processing
    executors[&quot;high_throughput&quot;] = graphbit.Executor.new_high_throughput(
        llm_config=llm_config,
        timeout_seconds=120,
        debug=False
    )

    # Low-latency executor - minimize response time
    executors[&quot;low_latency&quot;] = graphbit.Executor.new_low_latency(
        llm_config=llm_config,
        timeout_seconds=30,
        debug=False
    )

    # Memory-optimized executor - minimize memory usage
    executors[&quot;memory_optimized&quot;] = graphbit.Executor.new_memory_optimized(
        llm_config=llm_config,
        timeout_seconds=90,
        debug=False
    )

    return executors

def benchmark_executor_types(workflow, test_input):
    &quot;&quot;&quot;Benchmark different executor types.&quot;&quot;&quot;

    executors = create_optimized_executors()
    results = {}

    for executor_type, executor in executors.items():
        print(f&quot;Benchmarking {executor_type} executor...&quot;)

        start_time = time.time()

        try:
            result = executor.execute(workflow)
            duration_ms = (time.time() - start_time) * 1000

            results[executor_type] = {
                &quot;duration_ms&quot;: duration_ms,
                &quot;success&quot;: result.is_completed(),
                &quot;output_length&quot;: len(result.output()) if result.is_completed() else 0
            }

            print(f&quot;  ✅ {executor_type}: {duration_ms:.1f}ms&quot;)

        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            results[executor_type] = {
                &quot;duration_ms&quot;: duration_ms,
                &quot;success&quot;: False,
                &quot;error&quot;: str(e)
            }

            print(f&quot;  ❌ {executor_type}: Failed after {duration_ms:.1f}ms - {e}&quot;)

    return results
</code></pre>
<h2 id="resource-management">Resource Management</h2>
<h3 id="memory-optimization">Memory Optimization</h3>
<pre><code class="language-python">def create_memory_optimized_workflow():
    &quot;&quot;&quot;Create workflow optimized for memory usage.&quot;&quot;&quot;

    workflow = graphbit.Workflow(&quot;Memory Optimized Workflow&quot;)

    # Use concise prompts to reduce memory usage
    data_processor = graphbit.Node.agent(
        name=&quot;Memory Efficient Processor&quot;,
        prompt=&quot;Analyze: {input}&quot;,  # Concise prompt
        agent_id=&quot;mem_processor&quot;
    )

    # Data compressor using transform node
    compressor = graphbit.Node.transform(
        name=&quot;Data Compressor&quot;,
        transformation=&quot;uppercase&quot;  # Simple transformation to reduce data size
    )

    # Build memory-efficient workflow
    proc_id = workflow.add_node(data_processor)
    comp_id = workflow.add_node(compressor)

    workflow.connect(proc_id, comp_id)

    return workflow

def monitor_memory_usage():
    &quot;&quot;&quot;Monitor workflow memory usage.&quot;&quot;&quot;

    try:
        import psutil
        import os

        def get_memory_usage():
            &quot;&quot;&quot;Get current memory usage.&quot;&quot;&quot;
            process = psutil.Process(os.getpid())
            memory_info = process.memory_info()
            return {
                &quot;rss_mb&quot;: memory_info.rss / 1024 / 1024,  # MB
                &quot;vms_mb&quot;: memory_info.vms / 1024 / 1024,  # MB
                &quot;percent&quot;: process.memory_percent()
            }

        # Baseline memory
        baseline = get_memory_usage()
        print(f&quot;Baseline memory: {baseline['rss_mb']:.2f} MB&quot;)

        return baseline

    except ImportError:
        print(&quot;psutil not available for memory monitoring&quot;)
        return None

def execute_with_memory_monitoring(workflow, executor):
    &quot;&quot;&quot;Execute workflow with memory monitoring.&quot;&quot;&quot;

    baseline_memory = monitor_memory_usage()

    if baseline_memory:
        print(f&quot;Starting execution with {baseline_memory['rss_mb']:.2f} MB&quot;)

    # Execute workflow
    start_time = time.time()
    result = executor.execute(workflow)
    duration_ms = (time.time() - start_time) * 1000

    # Check memory after execution
    final_memory = monitor_memory_usage()

    if baseline_memory and final_memory:
        memory_increase = final_memory['rss_mb'] - baseline_memory['rss_mb']
        print(f&quot;Memory increase: {memory_increase:.2f} MB&quot;)
        print(f&quot;Execution completed in {duration_ms:.1f}ms&quot;)

    return result
</code></pre>
<h2 id="configuration-tuning">Configuration Tuning</h2>
<h3 id="environment-specific-optimization">Environment-Specific Optimization</h3>
<pre><code class="language-python">def get_optimized_config(environment=&quot;production&quot;, workload_type=&quot;balanced&quot;):
    &quot;&quot;&quot;Get optimized configuration for specific environment and workload.&quot;&quot;&quot;

    configs = {
        &quot;development&quot;: {
            &quot;model&quot;: &quot;gpt-4o-mini&quot;,
            &quot;timeout&quot;: 30
        },
        &quot;production&quot;: {
            &quot;model&quot;: &quot;gpt-4o-mini&quot;,
            &quot;timeout&quot;: 120
        }
    }

    workload_adjustments = {
        &quot;high_throughput&quot;: {
            &quot;model&quot;: &quot;gpt-4o-mini&quot;,  # Faster model
            &quot;timeout&quot;: 15
        },
        &quot;high_quality&quot;: {
            &quot;model&quot;: &quot;gpt-4o&quot;,  # Best quality model
            &quot;timeout&quot;: 180
        },
        &quot;low_latency&quot;: {
            &quot;model&quot;: &quot;gpt-4o-mini&quot;,
            &quot;timeout&quot;: 10
        }
    }

    base_config = configs.get(environment, configs[&quot;production&quot;])
    workload_config = workload_adjustments.get(workload_type, {})

    # Merge configurations
    final_config = {**base_config, **workload_config}

    return final_config

def create_optimized_executor(environment=&quot;production&quot;, workload_type=&quot;balanced&quot;):
    &quot;&quot;&quot;Create executor with optimized configuration.&quot;&quot;&quot;

    config_params = get_optimized_config(environment, workload_type)

    # LLM configuration
    llm_config = graphbit.LlmConfig.openai(
        api_key=os.getenv(&quot;OPENAI_API_KEY&quot;),
        model=config_params[&quot;model&quot;]
    )

    # Create executor based on workload type
    if workload_type == &quot;high_throughput&quot;:
        executor = graphbit.Executor.new_high_throughput(
            llm_config=llm_config,
            timeout_seconds=config_params[&quot;timeout&quot;],
            debug=False
        )
    elif workload_type == &quot;low_latency&quot;:
        executor = graphbit.Executor.new_low_latency(
            llm_config=llm_config,
            timeout_seconds=config_params[&quot;timeout&quot;],
            debug=False
        )
    elif workload_type == &quot;memory_optimized&quot;:
        executor = graphbit.Executor.new_memory_optimized(
            llm_config=llm_config,
            timeout_seconds=config_params[&quot;timeout&quot;],
            debug=False
        )
    else:
        executor = graphbit.Executor(
            config=llm_config,
            timeout_seconds=config_params[&quot;timeout&quot;],
            debug=False
        )

    return executor
</code></pre>
<h2 id="llm-client-optimization">LLM Client Optimization</h2>
<h3 id="client-configuration-and-performance">Client Configuration and Performance</h3>
<pre><code class="language-python">def create_optimized_llm_client():
    &quot;&quot;&quot;Create optimized LLM client for best performance.&quot;&quot;&quot;

    # OpenAI configuration with performance settings
    openai_config = graphbit.LlmConfig.openai(
        api_key=os.getenv(&quot;OPENAI_API_KEY&quot;),
        model=&quot;gpt-4o-mini&quot;  # Fast and cost-effective
    )

    # Create client
    client = graphbit.LlmClient(openai_config)

    # Warm up the client
    try:
        client.warmup()
        print(&quot;✅ Client warmed up successfully&quot;)
    except Exception as e:
        print(f&quot;⚠️ Client warmup failed: {e}&quot;)

    return client

def benchmark_llm_providers():
    &quot;&quot;&quot;Benchmark different LLM providers for performance.&quot;&quot;&quot;

    providers = {
        &quot;openai_gpt4o_mini&quot;: graphbit.LlmConfig.openai(
            api_key=os.getenv(&quot;OPENAI_API_KEY&quot;),
            model=&quot;gpt-4o-mini&quot;
        ),
        &quot;anthropic_claude&quot;: graphbit.LlmConfig.anthropic(
            api_key=os.getenv(&quot;ANTHROPIC_API_KEY&quot;),
            model=&quot;claude-3-5-sonnet-20241022&quot;
        ),
        &quot;ollama_llama&quot;: graphbit.LlmConfig.ollama(
            model=&quot;llama3.2&quot;
        )
    }

    test_prompt = &quot;Summarize this text in one sentence: {input}&quot;
    test_input = &quot;The quick brown fox jumps over the lazy dog.&quot;

    results = {}

    for provider_name, config in providers.items():
        print(f&quot;Testing {provider_name}...&quot;)

        try:
            client = graphbit.LlmClient(config)

            # Warm up
            client.warmup()

            # Time the completion
            start_time = time.time()

            response = client.complete(test_prompt, {&quot;input&quot;: test_input})

            duration_ms = (time.time() - start_time) * 1000

            # Get client statistics
            stats = client.get_stats()

            results[provider_name] = {
                &quot;duration_ms&quot;: duration_ms,
                &quot;success&quot;: True,
                &quot;response_length&quot;: len(response),
                &quot;stats&quot;: stats
            }

            print(f&quot;  ✅ {provider_name}: {duration_ms:.1f}ms&quot;)

        except Exception as e:
            results[provider_name] = {
                &quot;success&quot;: False,
                &quot;error&quot;: str(e)
            }
            print(f&quot;  ❌ {provider_name}: Failed - {e}&quot;)

    return results

def optimize_client_batch_processing():
    &quot;&quot;&quot;Demonstrate optimized batch processing.&quot;&quot;&quot;

    config = graphbit.LlmConfig.openai(
        api_key=os.getenv(&quot;OPENAI_API_KEY&quot;),
        model=&quot;gpt-4o-mini&quot;
    )

    client = graphbit.LlmClient(config)
    client.warmup()

    # Test data
    test_prompts = [
        &quot;Summarize: {text}&quot;,
        &quot;Extract key points: {text}&quot;,
        &quot;Analyze sentiment: {text}&quot;,
        &quot;Generate title: {text}&quot;
    ]

    test_texts = [
        &quot;The weather is beautiful today.&quot;,
        &quot;I'm frustrated with the slow service.&quot;,
        &quot;This product exceeds all expectations.&quot;,
        &quot;The meeting was productive and insightful.&quot;
    ]

    # Batch processing
    start_time = time.time()

    batch_inputs = []
    for prompt in test_prompts:
        for text in test_texts:
            batch_inputs.append({&quot;prompt&quot;: prompt, &quot;text&quot;: text})

    # Process batch
    batch_results = client.batch_complete(
        [(item[&quot;prompt&quot;], {&quot;text&quot;: item[&quot;text&quot;]}) for item in batch_inputs]
    )

    batch_duration_ms = (time.time() - start_time) * 1000

    print(f&quot;Batch processing ({len(batch_inputs)} items): {batch_duration_ms:.1f}ms&quot;)
    print(f&quot;Average per item: {batch_duration_ms / len(batch_inputs):.1f}ms&quot;)

    return batch_results
</code></pre>
<h2 id="workflow-design-patterns-for-performance">Workflow Design Patterns for Performance</h2>
<h3 id="efficient-workflow-patterns">Efficient Workflow Patterns</h3>
<pre><code class="language-python">def create_high_performance_patterns():
    &quot;&quot;&quot;Create various high-performance workflow patterns.&quot;&quot;&quot;

    patterns = {}

    # 1. Fan-out/Fan-in Pattern
    patterns[&quot;fan_out_in&quot;] = create_fan_out_fan_in_workflow()

    # 2. Pipeline Pattern
    patterns[&quot;pipeline&quot;] = create_pipeline_workflow()

    # 3. Conditional Processing Pattern
    patterns[&quot;conditional&quot;] = create_conditional_workflow()

    return patterns

def create_fan_out_fan_in_workflow():
    &quot;&quot;&quot;Create efficient fan-out/fan-in workflow.&quot;&quot;&quot;

    workflow = graphbit.Workflow(&quot;Fan-Out Fan-In Workflow&quot;)

    # Single input processor
    input_node = graphbit.Node.agent(
        name=&quot;Input Splitter&quot;,
        prompt=&quot;Split this input for parallel processing: {input}&quot;,
        agent_id=&quot;splitter&quot;
    )

    # Multiple parallel processors
    processors = []
    for i in range(3):
        processor = graphbit.Node.agent(
            name=f&quot;Processor {i+1}&quot;,
            prompt=f&quot;Process part {i+1}: {{split_input}}&quot;,
            agent_id=f&quot;processor_{i+1}&quot;
        )
        processors.append(processor)

    # Single aggregator
    aggregator = graphbit.Node.agent(
        name=&quot;Result Aggregator&quot;,
        prompt=&quot;Combine results: {processor_1_output}, {processor_2_output}, {processor_3_output}&quot;,
        agent_id=&quot;aggregator&quot;
    )

    # Build workflow
    input_id = workflow.add_node(input_node)
    processor_ids = [workflow.add_node(p) for p in processors]
    agg_id = workflow.add_node(aggregator)

    # Connect: input -&gt; all processors -&gt; aggregator
    for proc_id in processor_ids:
        workflow.connect(input_id, proc_id)
        workflow.connect(proc_id, agg_id)

    return workflow

def create_pipeline_workflow():
    &quot;&quot;&quot;Create efficient pipeline workflow.&quot;&quot;&quot;

    workflow = graphbit.Workflow(&quot;Pipeline Workflow&quot;)

    # Sequential processing stages
    stages = [
        (&quot;Data Validator&quot;, &quot;Validate input data: {input}&quot;),
        (&quot;Data Processor&quot;, &quot;Process validated data: {validated_data}&quot;),
        (&quot;Data Formatter&quot;, &quot;Format processed data: {processed_data}&quot;),
        (&quot;Quality Checker&quot;, &quot;Check quality: {formatted_data}&quot;)
    ]

    nodes = []
    for i, (name, prompt) in enumerate(stages):
        node = graphbit.Node.agent(
            name=name,
            prompt=prompt,
            agent_id=f&quot;stage_{i+1}&quot;
        )
        nodes.append(node)

    # Build pipeline
    node_ids = [workflow.add_node(node) for node in nodes]

    # Connect sequentially
    for i in range(len(node_ids) - 1):
        workflow.connect(node_ids[i], node_ids[i + 1])

    return workflow

def create_conditional_workflow():
    &quot;&quot;&quot;Create efficient conditional workflow.&quot;&quot;&quot;

    workflow = graphbit.Workflow(&quot;Conditional Workflow&quot;)

    # Input analyzer
    analyzer = graphbit.Node.agent(
        name=&quot;Input Analyzer&quot;,
        prompt=&quot;Analyze input type and complexity: {input}&quot;,
        agent_id=&quot;analyzer&quot;
    )

    # Condition node
    condition = graphbit.Node.condition(
        name=&quot;Complexity Check&quot;,
        expression=&quot;complexity == 'simple'&quot;
    )

    # Simple processor
    simple_processor = graphbit.Node.agent(
        name=&quot;Simple Processor&quot;,
        prompt=&quot;Quick processing: {input}&quot;,
        agent_id=&quot;simple_proc&quot;
    )

    # Complex processor
    complex_processor = graphbit.Node.agent(
        name=&quot;Complex Processor&quot;, 
        prompt=&quot;Detailed processing: {input}&quot;,
        agent_id=&quot;complex_proc&quot;
    )

    # Build conditional workflow
    analyzer_id = workflow.add_node(analyzer)
    condition_id = workflow.add_node(condition)
    simple_id = workflow.add_node(simple_processor)
    complex_id = workflow.add_node(complex_processor)

    # Connect: analyzer -&gt; condition -&gt; appropriate processor
    workflow.connect(analyzer_id, condition_id)
    workflow.connect(condition_id, simple_id)   # true branch
    workflow.connect(condition_id, complex_id)  # false branch

    return workflow
</code></pre>
<h2 id="performance-monitoring-and-profiling">Performance Monitoring and Profiling</h2>
<h3 id="real-time-performance-tracking">Real-time Performance Tracking</h3>
<pre><code class="language-python">def create_performance_profiler():
    &quot;&quot;&quot;Create performance profiler for workflows.&quot;&quot;&quot;

    class WorkflowProfiler:
        def __init__(self):
            self.execution_times = []
            self.node_times = {}
            self.memory_usage = []
            self.throughput_data = []

        def profile_execution(self, workflow, executor, iterations=1):
            &quot;&quot;&quot;Profile workflow execution.&quot;&quot;&quot;

            results = {
                &quot;total_iterations&quot;: iterations,
                &quot;execution_times&quot;: [],
                &quot;average_time&quot;: 0,
                &quot;throughput_per_second&quot;: 0,
                &quot;memory_peak&quot;: 0
            }

            print(f&quot;Profiling workflow with {iterations} iterations...&quot;)

            start_overall = time.time()

            for i in range(iterations):
                # Monitor memory before execution
                baseline_memory = monitor_memory_usage()

                # Time the execution
                start_time = time.time()
                result = executor.execute(workflow)
                execution_time = (time.time() - start_time) * 1000

                results[&quot;execution_times&quot;].append(execution_time)

                # Monitor memory after execution
                final_memory = monitor_memory_usage()

                if baseline_memory and final_memory:
                    memory_used = final_memory['rss_mb'] - baseline_memory['rss_mb']
                    results[&quot;memory_peak&quot;] = max(results[&quot;memory_peak&quot;], memory_used)

                print(f&quot;  Iteration {i+1}: {execution_time:.1f}ms&quot;)

            # Calculate statistics
            total_time_seconds = time.time() - start_overall
            results[&quot;average_time&quot;] = sum(results[&quot;execution_times&quot;]) / len(results[&quot;execution_times&quot;])
            results[&quot;throughput_per_second&quot;] = iterations / total_time_seconds

            return results

        def compare_configurations(self, workflow, configs):
            &quot;&quot;&quot;Compare different executor configurations.&quot;&quot;&quot;

            comparison_results = {}

            for config_name, executor in configs.items():
                print(f&quot;\nTesting configuration: {config_name}&quot;)

                profile_result = self.profile_execution(workflow, executor, iterations=3)
                comparison_results[config_name] = profile_result

            # Print comparison summary
            print(&quot;\n&quot; + &quot;=&quot;*50)
            print(&quot;Configuration Comparison Summary&quot;)
            print(&quot;=&quot;*50)

            for config_name, result in comparison_results.items():
                print(f&quot;{config_name}:&quot;)
                print(f&quot;  Average Time: {result['average_time']:.1f}ms&quot;)
                print(f&quot;  Throughput: {result['throughput_per_second']:.2f}/sec&quot;)
                print(f&quot;  Peak Memory: {result['memory_peak']:.2f}MB&quot;)

            return comparison_results

    return WorkflowProfiler()

def run_comprehensive_performance_test():
    &quot;&quot;&quot;Run comprehensive performance test.&quot;&quot;&quot;

    # Create test workflow
    workflow = create_parallel_workflow()

    # Create different executor configurations
    executors = create_optimized_executors()

    # Create profiler
    profiler = create_performance_profiler()

    # Run comparison
    results = profiler.compare_configurations(workflow, executors)

    # Find best performer
    best_config = min(results.keys(), key=lambda k: results[k][&quot;average_time&quot;])

    print(f&quot;\n🏆 Best performing configuration: {best_config}&quot;)
    print(f&quot;   Average time: {results[best_config]['average_time']:.1f}ms&quot;)
    print(f&quot;   Throughput: {results[best_config]['throughput_per_second']:.2f}/sec&quot;)

    return results
</code></pre>
<h2 id="caching-and-optimization-strategies">Caching and Optimization Strategies</h2>
<h3 id="response-caching">Response Caching</h3>
<pre><code class="language-python">def implement_response_caching():
    &quot;&quot;&quot;Implement response caching for repeated queries.&quot;&quot;&quot;

    import hashlib
    import json
    from typing import Dict, Any

    class CachedExecutor:
        def __init__(self, base_executor, cache_size=1000):
            self.base_executor = base_executor
            self.cache: Dict[str, Any] = {}
            self.cache_size = cache_size
            self.cache_hits = 0
            self.cache_misses = 0

        def _generate_cache_key(self, workflow, input_data=None):
            &quot;&quot;&quot;Generate cache key for workflow and input.&quot;&quot;&quot;

            # Create a hash of workflow structure and input
            workflow_str = str(workflow)
            input_str = json.dumps(input_data or {}, sort_keys=True)
            combined = workflow_str + input_str

            return hashlib.md5(combined.encode()).hexdigest()

        def execute(self, workflow, input_data=None):
            &quot;&quot;&quot;Execute workflow with caching.&quot;&quot;&quot;

            cache_key = self._generate_cache_key(workflow, input_data)

            # Check cache first
            if cache_key in self.cache:
                self.cache_hits += 1
                print(f&quot;💾 Cache hit for key: {cache_key[:8]}...&quot;)
                return self.cache[cache_key]

            # Execute workflow
            self.cache_misses += 1
            print(f&quot;🔄 Cache miss, executing workflow...&quot;)

            result = self.base_executor.execute(workflow)

            # Store in cache
            if len(self.cache) &gt;= self.cache_size:
                # Remove oldest entry (simple FIFO)
                oldest_key = next(iter(self.cache))
                del self.cache[oldest_key]

            self.cache[cache_key] = result

            return result

        def get_cache_stats(self):
            &quot;&quot;&quot;Get cache performance statistics.&quot;&quot;&quot;

            total_requests = self.cache_hits + self.cache_misses
            hit_rate = (self.cache_hits / total_requests) * 100 if total_requests &gt; 0 else 0

            return {
                &quot;cache_hits&quot;: self.cache_hits,
                &quot;cache_misses&quot;: self.cache_misses,
                &quot;hit_rate_percent&quot;: hit_rate,
                &quot;cache_size&quot;: len(self.cache)
            }

    return CachedExecutor

def test_caching_performance():
    &quot;&quot;&quot;Test caching performance improvement.&quot;&quot;&quot;

    # Create base executor
    base_executor = create_performance_optimized_executor()

    # Create cached executor
    CachedExecutorClass = implement_response_caching()
    cached_executor = CachedExecutorClass(base_executor)

    # Create simple test workflow
    workflow = graphbit.Workflow(&quot;Cache Test Workflow&quot;)

    test_agent = graphbit.Node.agent(
        name=&quot;Test Agent&quot;,
        prompt=&quot;Process this input: {input}&quot;,
        agent_id=&quot;test_agent&quot;
    )

    workflow.add_node(test_agent)

    # Test with repeated executions
    test_inputs = [&quot;test input 1&quot;, &quot;test input 2&quot;, &quot;test input 1&quot;]  # Repeat first input

    print(&quot;Testing caching performance...&quot;)

    for i, test_input in enumerate(test_inputs):
        print(f&quot;\nExecution {i+1} with input: '{test_input}'&quot;)

        start_time = time.time()
        result = cached_executor.execute(workflow)
        duration_ms = (time.time() - start_time) * 1000

        print(f&quot;Execution time: {duration_ms:.1f}ms&quot;)

    # Print cache statistics
    stats = cached_executor.get_cache_stats()
    print(f&quot;\nCache Statistics:&quot;)
    print(f&quot;  Hits: {stats['cache_hits']}&quot;)
    print(f&quot;  Misses: {stats['cache_misses']}&quot;)
    print(f&quot;  Hit Rate: {stats['hit_rate_percent']:.1f}%&quot;)
    print(f&quot;  Cache Size: {stats['cache_size']}&quot;)

    return stats
</code></pre>
<h2 id="best-practices">Best Practices</h2>
<h3 id="1-choose-the-right-executor-type">1. Choose the Right Executor Type</h3>
<pre><code class="language-python">def select_optimal_executor(workload_characteristics):
    &quot;&quot;&quot;Select optimal executor based on workload characteristics.&quot;&quot;&quot;

    recommendations = {
        &quot;high_volume_simple&quot;: &quot;high_throughput&quot;,
        &quot;real_time_interactive&quot;: &quot;low_latency&quot;, 
        &quot;resource_constrained&quot;: &quot;memory_optimized&quot;,
        &quot;balanced_workload&quot;: &quot;standard&quot;
    }

    workload_type = workload_characteristics.get(&quot;type&quot;, &quot;balanced_workload&quot;)
    recommended_executor = recommendations.get(workload_type, &quot;standard&quot;)

    print(f&quot;Recommended executor for '{workload_type}': {recommended_executor}&quot;)

    return recommended_executor
</code></pre>
<h3 id="2-model-selection-for-performance">2. Model Selection for Performance</h3>
<pre><code class="language-python">def select_optimal_model(use_case):
    &quot;&quot;&quot;Select optimal model based on use case.&quot;&quot;&quot;

    model_recommendations = {
        &quot;simple_tasks&quot;: &quot;gpt-4o-mini&quot;,
        &quot;complex_analysis&quot;: &quot;gpt-4o&quot;, 
        &quot;cost_sensitive&quot;: &quot;gpt-4o-mini&quot;,
        &quot;highest_quality&quot;: &quot;gpt-4o&quot;
    }

    recommended_model = model_recommendations.get(use_case, &quot;gpt-4o-mini&quot;)

    print(f&quot;Recommended model for '{use_case}': {recommended_model}&quot;)

    return recommended_model
</code></pre>
<h3 id="3-workflow-design-for-performance">3. Workflow Design for Performance</h3>
<pre><code class="language-python">def optimize_workflow_design():
    &quot;&quot;&quot;Guidelines for optimizing workflow design.&quot;&quot;&quot;

    guidelines = {
        &quot;minimize_sequential_dependencies&quot;: &quot;Use parallel processing where possible&quot;,
        &quot;optimize_prompt_length&quot;: &quot;Keep prompts concise and focused&quot;,
        &quot;batch_similar_operations&quot;: &quot;Group similar operations together&quot;,
        &quot;use_conditional_logic&quot;: &quot;Skip unnecessary processing with conditions&quot;,
        &quot;cache_common_operations&quot;: &quot;Cache frequently used results&quot;
    }

    for guideline, description in guidelines.items():
        print(f&quot;✅ {guideline}: {description}&quot;)

    return guidelines
</code></pre>
<h2 id="performance-testing-framework">Performance Testing Framework</h2>
<h3 id="automated-performance-testing">Automated Performance Testing</h3>
<pre><code class="language-python">def create_performance_test_suite():
    &quot;&quot;&quot;Create comprehensive performance test suite.&quot;&quot;&quot;

    class PerformanceTestSuite:
        def __init__(self):
            self.test_results = {}

        def run_latency_test(self, workflow, executor, iterations=10):
            &quot;&quot;&quot;Test execution latency.&quot;&quot;&quot;

            execution_times = []

            for i in range(iterations):
                start_time = time.time()
                result = executor.execute(workflow)
                duration_ms = (time.time() - start_time) * 1000
                execution_times.append(duration_ms)

            return {
                &quot;average_latency_ms&quot;: sum(execution_times) / len(execution_times),
                &quot;min_latency_ms&quot;: min(execution_times),
                &quot;max_latency_ms&quot;: max(execution_times),
                &quot;p95_latency_ms&quot;: sorted(execution_times)[int(len(execution_times) * 0.95)]
            }

        def run_throughput_test(self, workflow, executor, duration_seconds=60):
            &quot;&quot;&quot;Test execution throughput.&quot;&quot;&quot;

            start_time = time.time()
            executions = 0

            while (time.time() - start_time) &lt; duration_seconds:
                try:
                    result = executor.execute(workflow)
                    executions += 1
                except Exception as e:
                    print(f&quot;Execution failed: {e}&quot;)

            actual_duration = time.time() - start_time
            throughput = executions / actual_duration

            return {
                &quot;executions_completed&quot;: executions,
                &quot;test_duration_seconds&quot;: actual_duration,
                &quot;throughput_per_second&quot;: throughput
            }

        def run_stress_test(self, workflow, executor, max_concurrent=10):
            &quot;&quot;&quot;Test system under stress.&quot;&quot;&quot;

            import threading
            import queue

            results_queue = queue.Queue()

            def execute_workflow():
                try:
                    start_time = time.time()
                    result = executor.execute(workflow)
                    duration_ms = (time.time() - start_time) * 1000
                    results_queue.put({&quot;success&quot;: True, &quot;duration_ms&quot;: duration_ms})
                except Exception as e:
                    results_queue.put({&quot;success&quot;: False, &quot;error&quot;: str(e)})

            # Launch concurrent executions
            threads = []
            for i in range(max_concurrent):
                thread = threading.Thread(target=execute_workflow)
                threads.append(thread)
                thread.start()

            # Wait for all threads to complete
            for thread in threads:
                thread.join()

            # Collect results
            results = []
            while not results_queue.empty():
                results.append(results_queue.get())

            successful_executions = [r for r in results if r[&quot;success&quot;]]
            failed_executions = [r for r in results if not r[&quot;success&quot;]]

            return {
                &quot;total_executions&quot;: len(results),
                &quot;successful_executions&quot;: len(successful_executions),
                &quot;failed_executions&quot;: len(failed_executions),
                &quot;success_rate_percent&quot;: (len(successful_executions) / len(results)) * 100,
                &quot;average_duration_ms&quot;: sum(r[&quot;duration_ms&quot;] for r in successful_executions) / len(successful_executions) if successful_executions else 0
            }

        def run_complete_test_suite(self, workflow, executor):
            &quot;&quot;&quot;Run complete performance test suite.&quot;&quot;&quot;

            print(&quot;🧪 Running Performance Test Suite&quot;)
            print(&quot;=&quot;*40)

            # Latency test
            print(&quot;1. Latency Test...&quot;)
            latency_results = self.run_latency_test(workflow, executor)
            print(f&quot;   Average latency: {latency_results['average_latency_ms']:.1f}ms&quot;)

            # Throughput test
            print(&quot;2. Throughput Test...&quot;)
            throughput_results = self.run_throughput_test(workflow, executor, duration_seconds=30)
            print(f&quot;   Throughput: {throughput_results['throughput_per_second']:.2f}/sec&quot;)

            # Stress test
            print(&quot;3. Stress Test...&quot;)
            stress_results = self.run_stress_test(workflow, executor, max_concurrent=5)
            print(f&quot;   Success rate: {stress_results['success_rate_percent']:.1f}%&quot;)

            self.test_results = {
                &quot;latency&quot;: latency_results,
                &quot;throughput&quot;: throughput_results,
                &quot;stress&quot;: stress_results
            }

            return self.test_results

    return PerformanceTestSuite()

# Usage example
if __name__ == &quot;__main__&quot;:
    # Initialize GraphBit
    graphbit.init()

    # Create test workflow and executor
    test_workflow = create_memory_optimized_workflow()
    test_executor = create_performance_optimized_executor()

    # Run performance tests
    test_suite = create_performance_test_suite()
    results = test_suite.run_complete_test_suite(test_workflow, test_executor)

    print(&quot;\n📊 Performance Test Results Summary:&quot;)
    print(f&quot;Average Latency: {results['latency']['average_latency_ms']:.1f}ms&quot;)
    print(f&quot;Throughput: {results['throughput']['throughput_per_second']:.2f}/sec&quot;)
    print(f&quot;Stress Test Success Rate: {results['stress']['success_rate_percent']:.1f}%&quot;)
</code></pre>
<h2 id="whats-next">What's Next</h2>
<ul>
<li>Learn about <a href="../monitoring/">Monitoring</a> for tracking performance in production</li>
<li>Explore <a href="../reliability/">Reliability</a> for robust production systems</li>
<li>Check <a href="../validation/">Validation</a> for ensuring performance requirements</li>
<li>See <a href="../llm-providers/">LLM Providers</a> for provider-specific optimizations </li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.50899def.min.js"></script>
      
    
  </body>
</html>